{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "30367689_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LSazq5TQ2TjI",
        "NA4Dj2UyRbk1",
        "xYgoHVeDDI7P",
        "E3VFXal6N4cu",
        "NOnnJnqcIqb4",
        "K59SLLkSmIcD",
        "10JadfhAKc66",
        "kioaVP1WPIIl",
        "bgOaOcXRt-sx",
        "W6cKh5WduVYO",
        "BL93NrCYn9IO",
        "fe2aDk7Mum-d",
        "zokIEYwFwGC1",
        "efyfsCNwv1NJ",
        "YZkmCqoazyG7",
        "F9SoAsngEgVr",
        "G3kDVvI9TeNN",
        "byJKp4Mtur0u"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb58993808f94c9195fb1de771f12f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c5324d260f541fb8ead7cc7eed77a82",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff4f766aafc04576a87c36637dcbc6c4",
              "IPY_MODEL_9449c80a027f4d55980699a6b54df544"
            ]
          }
        },
        "6c5324d260f541fb8ead7cc7eed77a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff4f766aafc04576a87c36637dcbc6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_884599da9a2144868313e137f6a28484",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a1aaa4051ec407fad5ab533dbfbf759"
          }
        },
        "9449c80a027f4d55980699a6b54df544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61912c835f7e483199cf8a7e1a9b81de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [00:03&lt;00:00, 12.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_990cd4583de94e0bacdb78b5642a86ac"
          }
        },
        "884599da9a2144868313e137f6a28484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a1aaa4051ec407fad5ab533dbfbf759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61912c835f7e483199cf8a7e1a9b81de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "990cd4583de94e0bacdb78b5642a86ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee224c9de9844160bf5f6039741838d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_839acc48025d4187a2d4f0b5a8d9ec3c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ae97fe707c549359c92e00e3af70bb6",
              "IPY_MODEL_5051918e92ce43d5b1a67fb2f1cca57b"
            ]
          }
        },
        "839acc48025d4187a2d4f0b5a8d9ec3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ae97fe707c549359c92e00e3af70bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fab9113da9064ea68d810a61272a1a6f",
            "_dom_classes": [],
            "description": "Computing transition probabilities: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 36928,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 36928,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cd807c46a02422b8fddaf10e1b80a8e"
          }
        },
        "5051918e92ce43d5b1a67fb2f1cca57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b49240d65b447e29c86125d09a5f137",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 36928/36928 [00:22&lt;00:00, 1665.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fc9a5b40f374de282da588b37535954"
          }
        },
        "fab9113da9064ea68d810a61272a1a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cd807c46a02422b8fddaf10e1b80a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b49240d65b447e29c86125d09a5f137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fc9a5b40f374de282da588b37535954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA5EsPtK0sDq",
        "outputId": "a3f91a2c-8505-474a-ebae-9db83a014d0e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSazq5TQ2TjI"
      },
      "source": [
        "# Task 1: Recommender System Challenge "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA4Dj2UyRbk1"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZjdiJlx4Ki4",
        "outputId": "609d773d-c359-4612-a3b2-a57b875e5f75"
      },
      "source": [
        "!pip install implicit\n",
        "!pip install lightfm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting implicit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/07/c0121884722d16e2c5beeb815f6b84b41cbf22e738e4075f1475be2791bc/implicit-0.4.4.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from implicit) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from implicit) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from implicit) (4.41.1)\n",
            "Building wheels for collected packages: implicit\n",
            "  Building wheel for implicit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for implicit: filename=implicit-0.4.4-cp37-cp37m-linux_x86_64.whl size=3406409 sha256=133a2a150d5612dd6011f0b86944bd054dc10d598df118b8b2c91f6ffa98db78\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/d4/ec/fd4f622fcbefb7521f149905295b2c26adecb23af38aa28217\n",
            "Successfully built implicit\n",
            "Installing collected packages: implicit\n",
            "Successfully installed implicit-0.4.4\n",
            "Collecting lightfm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/fe/8864d723daa8e5afc74080ce510c30f7ad52facf6a157d4b42dec83dfab4/lightfm-1.16.tar.gz (310kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (0.22.2.post1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.0.1)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705359 sha256=2aeaf9bcaa4f64636d3491498b4afa458cc940c502e19494c998d13704a5f4cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/64/d4/673c7277f71ac4c5ad4835b94708c01b653ef2d3aa78ef20aa\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-EX6_XMpp1O"
      },
      "source": [
        "import implicit\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "import scipy.sparse as sparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from lightfm import LightFM"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYgoHVeDDI7P"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbs5gM8opp6r"
      },
      "source": [
        "# read data\n",
        "test_df = pd.read_csv('flickr_test_data.csv')\n",
        "train_df = pd.read_csv('flickr_train_data.csv')\n",
        "valid_df = pd.read_csv('flickr_validation_data.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3VFXal6N4cu"
      },
      "source": [
        "### NDCG function\n",
        "This function is used to get the NDCG score of the validation dataset, this score may have a positive relationship with the score in Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DkN1hEbpqLQ"
      },
      "source": [
        "# there is no rating, we treat all the rate is 1\n",
        "def NDCG(valid_gt, valid_perd):\n",
        "  DCG = []\n",
        "  # get all the use-items\n",
        "  GT = valid_gt[valid_gt['rating'] == 1]\n",
        "  for i in range(len(GT)):\n",
        "    # the use_id and correspoding item \n",
        "    # (only one item per person in valid data set)\n",
        "    user_id = GT.iloc[i]['user_id']\n",
        "    item_id = GT.iloc[i]['item_id']\n",
        "    # find the items we recommended to user i\n",
        "    user_item = list(valid_perd[valid_perd['user_id'] == i]['item_id'])\n",
        "    # if it shows in the 15, we get the DCG\n",
        "     # if not we just take 0\n",
        "    if item_id in user_item:\n",
        "      rank = user_item.index(item_id) + 1\n",
        "      # rank 1\n",
        "      if rank == 1:\n",
        "        DCG.append(1)\n",
        "      # rest\n",
        "      else:\n",
        "        DCG.append(1/math.log(rank, 2))\n",
        "    else: \n",
        "      DCG.append(0)\n",
        "  # the average DCG of each person is the NDCG of the recommendations\n",
        "  # (trate the ground true is 1)\n",
        "  return np.mean(DCG)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOnnJnqcIqb4"
      },
      "source": [
        "### Recommend funciton for ALS and LMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch3OiSqdppyt"
      },
      "source": [
        "def recommend(user_id, sparse_user_item, user_vecs, item_vecs, test_df):\n",
        "    # Get the interactions scores from the sparse person content matrix\n",
        "    user_interactions = sparse_user_item[user_id,:].toarray()\n",
        "    # Add 1 to everything, so that articles with no interaction yet become equal to 1\n",
        "    user_interactions = user_interactions.reshape(-1) + 1\n",
        "    # Make articles already interacted zero\n",
        "    user_interactions[user_interactions > 1] = 0\n",
        "    # Get dot product of person vector and all content vectors\n",
        "    rec_vector = user_vecs[user_id,:].dot(item_vecs.T).toarray()\n",
        "    \n",
        "    # Scale this recommendation vector between 0 and 1\n",
        "    min_max = MinMaxScaler()\n",
        "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
        "    # Content already interacted have their recommendation multiplied by zero\n",
        "    recommend_vector = user_interactions * rec_vector_scaled\n",
        "\n",
        "    # Start empty list to store items and scores\n",
        "    items = []\n",
        "    scores = []\n",
        "    test_item_id = test_df[test_df['user_id'] == user_id]['item_id']\n",
        "    for i in test_item_id:\n",
        "        items.append(i)\n",
        "        scores.append(recommend_vector[i])\n",
        "    # record the score of all 100 items\n",
        "    recommendations = pd.DataFrame({'user_id': user_id, 'item_id': items, 'score': scores})\n",
        "    # get the top 15 recommend items\n",
        "    recommendations = recommendations.sort_values(by='score', ascending = False)[:15]\n",
        "    return recommendations\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K59SLLkSmIcD"
      },
      "source": [
        "## ALS\n",
        "\n",
        "Among all the above recommendation system models, ALS with adjusted parameters has the best performance, reaching 0.253 in the NDCG of the verification set, and getting a score of 0.22 in Kaggle in the predicted test data. The larger k is, the more accurate it will be, but the longer the calculation time will be. However, at the same time, the data set we get is not large. Blindly increasing the number of hidden variables will only lead to overfitting, which may reduce the accuracy of our recommendation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evFIsTfPpqAi"
      },
      "source": [
        "#convert to sparse matrix\n",
        "sparse_item_user = sparse.csr_matrix((train_df['rating'].astype(float), (train_df['item_id'], train_df['user_id'])))\n",
        "sparse_user_item = sparse.csr_matrix((train_df['rating'].astype(float), (train_df['user_id'], train_df['item_id'])))"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMXQOeAVpqFy"
      },
      "source": [
        "# The rate in which we'll increase our confidence in a preference with more interactions.\n",
        "alpha = 60\n",
        "data = (sparse_item_user * alpha).astype('double')"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "bb58993808f94c9195fb1de771f12f7d",
            "6c5324d260f541fb8ead7cc7eed77a82",
            "ff4f766aafc04576a87c36637dcbc6c4",
            "9449c80a027f4d55980699a6b54df544",
            "884599da9a2144868313e137f6a28484",
            "9a1aaa4051ec407fad5ab533dbfbf759",
            "61912c835f7e483199cf8a7e1a9b81de",
            "990cd4583de94e0bacdb78b5642a86ac"
          ]
        },
        "id": "gNL1RjwdreSK",
        "outputId": "4976c11e-2425-4971-9014-4f65aac720a7"
      },
      "source": [
        "# create and fit the model\n",
        "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=350, iterations=50)\n",
        "model.fit(data)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:implicit:GPU training requires factor size to be a multiple of 32. Increasing factors from 20 to 32.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb58993808f94c9195fb1de771f12f7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10JadfhAKc66"
      },
      "source": [
        "### Test the NDCG score in validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLnsO_K1pqHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa985341-4eeb-4073-ddc1-153fb49d0c79"
      },
      "source": [
        "# Get the trained person and content vectors. We convert them to csr matrices\n",
        "user_vecs = sparse.csr_matrix(model.user_factors)\n",
        "item_vecs = sparse.csr_matrix(model.item_factors)\n",
        "\n",
        "user_id_list = []\n",
        "item_id_list = []\n",
        "\n",
        "for user_id in set(valid_df['user_id']):\n",
        "  recommendations = recommend(user_id, sparse_user_item, user_vecs, item_vecs, valid_df)\n",
        "  user_id_list += list(recommendations['user_id'])\n",
        "  item_id_list += list(recommendations['item_id'])\n",
        "valid_rec = pd.DataFrame({'user_id': user_id_list, 'item_id': item_id_list})\n",
        "\n",
        "print('The NDCG score in validation dataset is: ', NDCG(valid_df, valid_rec))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The NDCG score in validation dataset is:  0.25314880128637063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kioaVP1WPIIl"
      },
      "source": [
        "### Apply the model in test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POIxYDlwreZA"
      },
      "source": [
        "# Get the trained person and content vectors. We convert them to csr matrices\n",
        "user_vecs = sparse.csr_matrix(model.user_factors)\n",
        "item_vecs = sparse.csr_matrix(model.item_factors)\n",
        "\n",
        "user_id_list = []\n",
        "item_id_list = []\n",
        "\n",
        "for user_id in set(test_df['user_id']):\n",
        "  recommendations = recommend(user_id, sparse_user_item, user_vecs, item_vecs, test_df)\n",
        "  user_id_list += list(recommendations['user_id'])\n",
        "  item_id_list += list(recommendations['item_id'])\n",
        "\n",
        "ouput_df = pd.DataFrame({'user_id': user_id_list, 'item_id': item_id_list})\n",
        "ouput_df.to_csv('data_df.csv',index=False)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgOaOcXRt-sx"
      },
      "source": [
        "## LMF\n",
        "\n",
        "Compared with ALS and FM, they both carry out implicit matrix decomposition and can solve the sparse matrix decomposition problem through different algorithms. Theoretically, FM runs faster than ALS because the time complexity of the FM training step and prediction step is linear. Compared with ALS, FM's model is more general, and it can be applied to any situation with real numbers. These two models are similar, they all based on matrix decomposition, the reason of LMF only take 0.15 is the use of parameter may different between ALS.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSBPhQojKMS8",
        "outputId": "93236ca6-f4dc-45d8-83d2-c682cb3dbd76"
      },
      "source": [
        "# create and fit the model\n",
        "model = implicit.lmf.LogisticMatrixFactorization(factors=32, regularization=350, iterations=60)\n",
        "model.fit(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [00:03<00:00, 15.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6cKh5WduVYO"
      },
      "source": [
        "### Test the NDCG score in validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB4oR5IJKMVV",
        "outputId": "501d7b41-e039-43c1-d001-3aa021da64fa"
      },
      "source": [
        "# Get the trained person and content vectors. We convert them to csr matrices\n",
        "user_vecs = sparse.csr_matrix(model.user_factors)\n",
        "item_vecs = sparse.csr_matrix(model.item_factors)\n",
        "\n",
        "user_id_list = []\n",
        "item_id_list = []\n",
        "\n",
        "for user_id in set(valid_df['user_id']):\n",
        "  recommendations = recommend(user_id, sparse_user_item, user_vecs, item_vecs, valid_df)\n",
        "  user_id_list += list(recommendations['user_id'])\n",
        "  item_id_list += list(recommendations['item_id'])\n",
        "valid_rec = pd.DataFrame({'user_id': user_id_list, 'item_id': item_id_list})\n",
        "\n",
        "print('The NDCG score in validation dataset is: ', NDCG(valid_df, valid_rec))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The NDCG score in validation dataset is:  0.1479774464720333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL93NrCYn9IO"
      },
      "source": [
        "## Light FM\n",
        "\n",
        "The algorithm principle of Light-FM with only use training dataset is the same as the MF method. By testing different loss functions in Light-FM, we can see that LMF and Light-FM models have similar performance. I think that if I can adjust the parameters to a correct range, these two models can have the same performance as the ALS model.\n",
        "The score obtained by LightFM using features of users and items is not ideal. The highest NDCG in the validation dataset with loss function BPR is only 0.059, which is inconsistent with my expectation. It may be because all our data sets are not large enough, and the prediction using features can only represent part of the time period. Or because the features does not match the training data, which will reduce the accuracy of our prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWHwOAaFtwbq",
        "outputId": "15b6e871-96d2-459e-b59c-e6359a262680"
      },
      "source": [
        "#model = LightFM(loss='warp-kos', k=15)\n",
        "#model = LightFM(loss='logistic') #0.158227\n",
        "#model = LightFM(loss='bpr')#0.15682\n",
        "#model.fit(data.T, user_features = user_features, item_features = item_features, epochs=10, num_threads=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.05 s, sys: 6.77 ms, total: 7.06 s\n",
            "Wall time: 3.57 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f7f25ff69d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2aDk7Mum-d"
      },
      "source": [
        "### LightMF using train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4G1jv9W0GpW"
      },
      "source": [
        "def test(loss):\n",
        "  model = LightFM(no_components = 25, loss=loss)# 25:0.178 real 0.15565\n",
        "  model.fit(data.T, epochs=30, num_threads=2)\n",
        "  user_ids = list(set(valid_df['user_id']))\n",
        "  item_ids = list(valid_df.groupby('user_id')['item_id'].apply(list))\n",
        "  #user_ids = list(set(test_df['user_id']))\n",
        "  #item_ids = list(test_df.groupby('user_id')['item_id'].apply(list))\n",
        "\n",
        "  user_id_list = []\n",
        "  item_id_list = []\n",
        "\n",
        "  for i in user_ids:\n",
        "    # get the predicted score of each item\n",
        "    predictions = model.predict(i, item_ids[i], num_threads=4)\n",
        "\n",
        "    recommendations = pd.DataFrame({'user_id': i, 'item_id': item_ids[i], 'score': predictions})\n",
        "    recommendations = recommendations.sort_values(by='score', ascending = False)[:15] \n",
        "    # print(recommendations)\n",
        "    user_id_list += list(recommendations['user_id'])\n",
        "    item_id_list += list(recommendations['item_id'])\n",
        "\n",
        "  valid_rec = pd.DataFrame({'user_id': user_id_list, 'item_id': item_id_list})\n",
        "  print('NDCG score of LightFM using error function', loss , 'is :', NDCG(valid_df, valid_rec))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zokIEYwFwGC1"
      },
      "source": [
        "#### The NDCG score of different error function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krKuN4UXt5VW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2ca1ab-996a-4584-a736-81a99776b5c3"
      },
      "source": [
        "loss = ['warp', 'logistic', 'warp-kos', 'bpr']\n",
        "for i in loss:\n",
        "  test(i)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NDCG score of LightFM using warp is : 0.17979786284622803\n",
            "NDCG score of LightFM using logistic is : 0.1477172451104682\n",
            "NDCG score of LightFM using warp-kos is : 0.1526017947356816\n",
            "NDCG score of LightFM using bpr is : 0.17435181416276796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efyfsCNwv1NJ"
      },
      "source": [
        "### LightMF using train data, item feature and user feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puWaLhpumXGp"
      },
      "source": [
        "# load the feature data\n",
        "item_fea = pd.read_csv('flickr_item_fea.csv')\n",
        "user_fea = pd.read_csv('flickr_user_fea.csv')\n",
        "\n",
        "user_ids = list(set(valid_df['user_id']))\n",
        "item_ids = list(valid_df.groupby('user_id')['item_id'].apply(list))\n",
        "# this part is for predict base on test data\n",
        "#user_ids = list(set(test_df['user_id']))\n",
        "#item_ids = list(test_df.groupby('user_id')['item_id'].apply(list))\n",
        "\n",
        "# trasform the feature dataframe into sparse matrix\n",
        "user_features = sparse.csr_matrix(user_fea.values)\n",
        "item_features = sparse.csr_matrix(item_fea.values)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jWPmA6AJ_lL"
      },
      "source": [
        "def test_fea(loss):\n",
        "  # The rate in which we'll increase our confidence in a preference with more interactions.\n",
        "  alpha = 2 \n",
        "  data = (sparse_item_user * alpha).astype('double')\n",
        "  # create and fit the model\n",
        "  model = LightFM(loss=loss)\n",
        "  model.fit(data.T, user_features = user_features, item_features = item_features, epochs=10, num_threads=10)\n",
        "\n",
        "  user_id_list = []\n",
        "  item_id_list = []\n",
        "\n",
        "  for i in user_ids:\n",
        "    predictions = model.predict(i, item_ids[i], user_features=user_features,\n",
        "                                item_features=item_features, num_threads=4)\n",
        "    recommendations = pd.DataFrame({'user_id': i, 'item_id': item_ids[i], 'score': predictions})\n",
        "    recommendations = recommendations.sort_values(by='score', ascending = False)[:15] \n",
        "\n",
        "    user_id_list += list(recommendations['user_id'])\n",
        "    item_id_list += list(recommendations['item_id'])\n",
        "  # get the recommendations\n",
        "  valid_rec = pd.DataFrame({'user_id': user_id_list, 'item_id': item_id_list})\n",
        "  print('NDCG score of LightFM using error function', loss , 'is :', NDCG(valid_df, valid_rec))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZkmCqoazyG7"
      },
      "source": [
        "#### The NDCG score of different error function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EydrbsyyJV48",
        "outputId": "af77c668-a04a-4cf3-c6b5-de3b2be6dbc8"
      },
      "source": [
        "for i in loss:\n",
        "  test_fea(i)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NDCG score of LightFM using error function warp is : 0.04878550597605831\n",
            "NDCG score of LightFM using error function logistic is : 0.05012234405657364\n",
            "NDCG score of LightFM using error function warp-kos is : 0.050443260893844336\n",
            "NDCG score of LightFM using error function bpr is : 0.059241248193599674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9SoAsngEgVr"
      },
      "source": [
        "## Neural Network Model\n",
        "\n",
        "The accuracy of the neural network is only about 0.6 and is very unstable, sometimes the training error is 0.4, but in the validation set NDCG is only 0.1, this may be because I use only two hidden layers neural network, and only 10 hidden neurons, compared to the training set in the neural network is small, it is also the cause of the result is not stable. Another reason is that neural network needs a large amount of data for training, and our data set is too small to complete the training of the large-scale neural network, which is also the reason why I did not choose to use a neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSeKNIPemOoD"
      },
      "source": [
        "# Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes.\n",
        "# Here we could get better results by keep playing with regularization.\n",
        "class CollabFNet(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
        "        super(CollabFNet, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
        "        self.lin2 = nn.Linear(n_hidden, 1)\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        x = F.relu(torch.cat([U, V], dim=1))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS9PLwc_mOuo"
      },
      "source": [
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "        users = torch.LongTensor(train_df.user_id.values) # .cuda()\n",
        "        items = torch.LongTensor(train_df.item_id.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(train_df.rating.values) #.cuda()\n",
        "        if unsqueeze:\n",
        "            ratings = ratings.unsqueeze(1)\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss.item()) \n",
        "    y_hat = test_loss(model, unsqueeze)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0f1THMkKDux"
      },
      "source": [
        "# this function give the loss in validation data\n",
        "def test_loss(model, unsqueeze=False):\n",
        "    model.eval()\n",
        "    # turn the matix to tensor\n",
        "    users = torch.LongTensor(valid_df.user_id.values) #.cuda()\n",
        "    items = torch.LongTensor(valid_df.item_id.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(valid_df.rating.values) #.cuda()\n",
        "    if unsqueeze:\n",
        "        ratings = ratings.unsqueeze(1)\n",
        "    # predict the score of each item\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX-6Ox_7ETZe"
      },
      "source": [
        "# this function take the model and output the 15 recommendations of valid data\n",
        "def nn_recom(model, unsqueeze=False):\n",
        "  user_id_list = []\n",
        "  item_id_list = []\n",
        "  for i in range(num_users):\n",
        "    items = torch.LongTensor(valid_df[valid_df['user_id'] ==i].item_id.values)\n",
        "    users = torch.LongTensor(valid_df[valid_df['user_id'] ==i].user_id.values)\n",
        "    scores = model(users, items)\n",
        "    # record the score of all 100 items\n",
        "    recommendations = pd.DataFrame({'user_id': users.tolist(), 'item_id': items.tolist(), 'score': scores.tolist()})\n",
        "    # get the top 15 recommend items\n",
        "    recommendations = recommendations.sort_values(by='score', ascending = False)[:15]\n",
        "    user_id_list += list(recommendations['user_id'])\n",
        "    item_id_list += list(recommendations['item_id'])\n",
        "  valid_rec = pd.DataFrame({'user_id': user_id_list, 'item_id': item_id_list})\n",
        "  return valid_rec"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVh6HPqQzniU"
      },
      "source": [
        "# get the number of users and the number of items\n",
        "num_users = len(set(list(train_df.user_id)))\n",
        "num_items = len(set(list(train_df.item_id)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3kDVvI9TeNN"
      },
      "source": [
        "### The NDCG score of NN in valid dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0tOh9g-s5q9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c874e85f-ace3-48d4-aa49-e3db8548b4c6"
      },
      "source": [
        "# create model\n",
        "model = CollabFNet(num_users, num_items, emb_size=100) #.cuda()\n",
        "# train model\n",
        "train_epocs(model, epochs=10, lr=0.1,  wd=3, unsqueeze=True)\n",
        "# get the 15 recommendations\n",
        "predict = nn_recom(model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6616938710212708\n",
            "3.9662060737609863\n",
            "0.5383036732673645\n",
            "1.099510908126831\n",
            "0.8639771342277527\n",
            "0.44130101799964905\n",
            "0.1430162638425827\n",
            "0.10928338021039963\n",
            "0.36615920066833496\n",
            "0.6584334373474121\n",
            "test loss 0.085 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upXIqvZ9K2Od",
        "outputId": "9ec22248-4561-4786-d705-27e920fe8ced"
      },
      "source": [
        "NDCG(valid_df, predict)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06204013904567362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byJKp4Mtur0u"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "After comparing the NDCG score of the validation set and the half test set on Kagge, at present, ALS has the best performance with the NDCG score of 0.22. However, I think MF and Light-Fm only use the training set, can get a good score after adjusting the parameters because they are both based on the matrix decomposition method. For the Light-FM using user-item features, we cannot prove that the features are related to the training set. However, I think it will save time if features are used to predict in a large-scale recommendation system, and the accuracy can be improved by combining the user and item features with the training data. In the neural network model, due to our lack of data and use of a simple neural network, we can only get a low NDCG score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVMeBa4BVesC"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV4w8_1PcEsk"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dnSN4fDJtnE",
        "outputId": "0ecf7af9-317c-497f-add6-a65179129b3a"
      },
      "source": [
        "!pip install Node2Vec\n",
        "from node2vec import Node2Vec"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Node2Vec in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from Node2Vec) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Node2Vec) (4.41.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from Node2Vec) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Node2Vec) (1.19.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from Node2Vec) (2.5.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->Node2Vec) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->Node2Vec) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->Node2Vec) (5.0.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->Node2Vec) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td9xRm-DZBy3",
        "outputId": "047b931c-1ea4-46ff-dd01-b8137cad440c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from gensim.models import Word2Vec\n",
        "import scipy.sparse.linalg as linalg\n",
        "import scipy.cluster.hierarchy as hr\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import torch\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f261a005150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FotM2EzFcGV4"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9IUv6DdeNMx"
      },
      "source": [
        "# get the document and same into a dictionary\n",
        "docs = open('docs.txt')\n",
        "docs_dic = {}\n",
        "for i in docs.readlines():\n",
        "  docs_dic[int(i.split(' ', 1)[0])] = i.split(' ', 1)[1].strip()\n",
        "docs.close()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ght6fQKv0s0_",
        "outputId": "0220a5e8-7913-43d2-9744-4a6962ba517b"
      },
      "source": [
        "# show the dict\n",
        "list(docs_dic.items())[:5]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(12828558,\n",
              "  'Assessing Local Institutional Capacity, Data Availability, and Outcomes by'),\n",
              " (66779408,\n",
              "  'THE PROSPECTS FOR INTERNET TELEPHONY IN EUROPE AND LATIN AMERICA TPP 127 Telecom Modeling and Policy Analysis'),\n",
              " (38902949,\n",
              "  'Economic Shocks, Safety Nets, and Fiscal Constraints: Social Protection for the Poor in Latin America'),\n",
              " (33450563, 'Reform, Growth, and Poverty in Vietnam'),\n",
              " (57470294,\n",
              "  'Households and Economic Growth in Latin America and the Caribbean')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHv4DUGHpqq-"
      },
      "source": [
        "# get the ture label of each node\n",
        "labels_txt = open('labels.txt')\n",
        "node_list = []\n",
        "lable_list = []\n",
        "for i in labels_txt.readlines():\n",
        "  node_list += [int(i.strip().split(' ')[0])]\n",
        "  lable_list+= [int(i.strip().split(' ')[1])]\n",
        "labels_df = pd.DataFrame({'node': node_list, 'true_label': lable_list})       \n",
        "labels_txt.close()\n",
        "\n",
        "# get the true lable list\n",
        "true_label = list(labels_df['true_label'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9YdyZ0DpqtD"
      },
      "source": [
        "# we get the k clusters we need to clustering from true label\n",
        "k = len(set(list(labels_df['true_label'])))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neHRPnfkDiAk"
      },
      "source": [
        "## K-means fucniton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5SVnpLcDhTN"
      },
      "source": [
        "# take the embedding matrix as the input\n",
        "# output the predicted lables by kmeans \n",
        "def kmeans(X):\n",
        "  kmeans = KMeans(init='k-means++', n_clusters=k, n_init=50)\n",
        "  kmeans.fit_predict(X)\n",
        "  centroids = kmeans.cluster_centers_\n",
        "  # get the clustering lables\n",
        "  labels = kmeans.labels_\n",
        "  return labels"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9GDiRrgm8t0"
      },
      "source": [
        "## Create graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufj8Lfw-arf-"
      },
      "source": [
        "G = nx.read_adjlist('adjedges.txt', create_using = nx.DiGraph(), nodetype = int)\n",
        "# make the graph to undirected graph\n",
        "G = nx.to_undirected(G)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLjhu9v15x5-",
        "outputId": "5798fe38-24ee-41a3-b6b9-2e3e413def55"
      },
      "source": [
        "print('There are', len(G.nodes()), 'nodes,', 'and', len(G.edges()), 'edges in graph G.')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 36928 nodes, and 54328 edges in graph G.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsoB4NlX6VDD",
        "outputId": "67ee8dd1-952f-45cc-9401-8196d9b3acc8"
      },
      "source": [
        "# check how many sub-graph in G\n",
        "i = 0\n",
        "for subg in nx.connected_components(G):\n",
        "  i += 1\n",
        "print('There are', i, 'numbers of sub-graph in G.')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 10440 numbers of sub-graph in G.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3sltQDR2K8W"
      },
      "source": [
        "There are 36928 nodes in the graph, but the are only 18720 nodes we need, we need to extract them form the embedding, then use kmeans to predict the label to do the clusering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt7O-Sxf5-jG"
      },
      "source": [
        "# add the node id then left join two dataframe then remove the id \n",
        "# as the embedding matrix to apply kmeans\n",
        "def getdocnode(embedding_vec):\n",
        "  vec = pd.DataFrame(embedding_vec)\n",
        "  # all the nodes in the graph\n",
        "  all_nodes = pd.DataFrame(G.nodes, columns=['node_id'])\n",
        "  # link the node and predicted label\n",
        "  all_nodes_vec = pd.concat([all_nodes, vec],axis=1)\n",
        "  doc_ids = pd.DataFrame(list(docs_dic.keys()), columns=['node_id'])\n",
        "  # get the node we use(documents)\n",
        "  node_vec = doc_ids.merge(all_nodes_vec, on = 'node_id', how = 'left').iloc[:,1:]\n",
        "  return node_vec"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnzc6iVYIyTd"
      },
      "source": [
        " ## Spectral Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2TuutZSiMkp"
      },
      "source": [
        "### Get the eigenvalues and eigenvectors of the matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amtTg9lkFV5o"
      },
      "source": [
        "# get the laplacian matrix\n",
        "L = nx.laplacian_matrix(G).astype(float)\n",
        "# compute eigenvalues and eigenvectors of the matrix.\n",
        "w,v = sp.sparse.linalg.eigsh(L, k = 5, which='SM')\n",
        "X = w * v"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlKoWFx_iTbk"
      },
      "source": [
        "### Apply kmeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cbq3bFCEVRf"
      },
      "source": [
        "# take only nodes shows in the document id\n",
        "node_vec_sc = getdocnode(X)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuFTMfs1z1ne"
      },
      "source": [
        "# get the lables predicted by kmeans\n",
        "labels_sc = kmeans(node_vec_sc)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLY_ZHdZZbfF"
      },
      "source": [
        "### The nmi score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bx7NXhWZXQF",
        "outputId": "b20c2852-833e-4719-dfa1-143e4ab422ab"
      },
      "source": [
        "# calculate the nmi score\n",
        "nmi_sc = normalized_mutual_info_score(true_label, labels_sc)\n",
        "print('the nmi score of Spectral Clustering is: ', nmi_sc)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the nmi score of Spectral Clustering is:  0.056940878168318824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCc9KKqoifQk"
      },
      "source": [
        "## Node clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnEZyZV0VXU8"
      },
      "source": [
        "### node2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ee224c9de9844160bf5f6039741838d7",
            "839acc48025d4187a2d4f0b5a8d9ec3c",
            "3ae97fe707c549359c92e00e3af70bb6",
            "5051918e92ce43d5b1a67fb2f1cca57b",
            "fab9113da9064ea68d810a61272a1a6f",
            "2cd807c46a02422b8fddaf10e1b80a8e",
            "1b49240d65b447e29c86125d09a5f137",
            "9fc9a5b40f374de282da588b37535954"
          ]
        },
        "id": "j-uhzV1JxpdW",
        "outputId": "880ade9a-e2c8-4e17-e454-59d907c54d63"
      },
      "source": [
        "#pre-compute the probabilities and generate walks :\n",
        "node2vec = Node2Vec(G, dimensions=64, walk_length=10, num_walks=5, workers=16)\n",
        "# nodes embedding\n",
        "model_node2vec = node2vec.fit(window=10, min_count=2, batch_words=10)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee224c9de9844160bf5f6039741838d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Computing transition probabilities', max=36928.0, style=P…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W85aDi6_AOUj"
      },
      "source": [
        "### Apply kmeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LC4v8wKxonB"
      },
      "source": [
        "# get the embedding matrix we use\n",
        "node_vec = getdocnode(model_node2vec.wv.vectors)\n",
        "# get the lables predicted by kmeans\n",
        "labels_node2vec = kmeans(node_vec)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta-cXewNZSRF"
      },
      "source": [
        "### The nmi score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggyUWHKtZSW9",
        "outputId": "8f70bb82-34fd-4642-c968-9b772fa7789e"
      },
      "source": [
        "# comput the nmi score\n",
        "nmi_sc = normalized_mutual_info_score(true_label, list(labels_node2vec))\n",
        "print('The nmi score of Node embedding with k-means is: ', nmi_sc)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nmi score of Node embedding with k-means is:  0.3024426634326591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGs3OkG6zIpI"
      },
      "source": [
        "## Text clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5izpuj62VJyV"
      },
      "source": [
        "### Tokenize and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtECsbezpqpB"
      },
      "source": [
        "# to store the tokens of each title\n",
        "titles = []\n",
        "for text in list(docs_dic.values()):\n",
        "    # get only word in the text, this step can remove number\n",
        "    tokens = tokenizer.tokenize(text.lower())\n",
        "    # stemming\n",
        "    stem = [stemmer.stem(w) for w in tokens]\n",
        "    titles.append(stem)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95oB5XGPBAS2",
        "outputId": "d3cf12ad-1145-4923-a47b-3cbe7cd21e03"
      },
      "source": [
        "# show the tokens\n",
        "titles[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['assess',\n",
              " 'local',\n",
              " 'institut',\n",
              " 'capac',\n",
              " 'data',\n",
              " 'avail',\n",
              " 'and',\n",
              " 'outcom',\n",
              " 'by']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC34Mk46VNnG"
      },
      "source": [
        "### word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V2PU5CdBKiP"
      },
      "source": [
        "This function is use to turn word embedding to sentence embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6nvMPdMCaY_"
      },
      "source": [
        "def sent_vectorizer(sent, model):\n",
        "    sent_vec =[]\n",
        "    numw = 0\n",
        "    for w in sent:\n",
        "        try:\n",
        "            if numw == 0:\n",
        "                sent_vec = model[w]\n",
        "            else:\n",
        "                sent_vec = np.add(sent_vec, model[w])\n",
        "            numw+=1\n",
        "        except:\n",
        "            pass\n",
        "    return np.asarray(sent_vec) / numw"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FndOnTYA01W8"
      },
      "source": [
        "# train the word2vec model\n",
        "model_word2vec = Word2Vec(titles, min_count=0)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhK2Y9wzH6Bb",
        "outputId": "d57c288a-0214-4762-e6f6-ca944a1dbfee"
      },
      "source": [
        "# the embedding matrix of document\n",
        "text_vec_list = []\n",
        "for sentence in titles:\n",
        "    text_vec_list.append(sent_vectorizer(sentence, model_word2vec))\n",
        "# turn the array in array to a dataframe\n",
        "text_vec_df = pd.DataFrame(text_vec_list)\n",
        "# turn the NaN values to number\n",
        "text_vec = np.nan_to_num(text_vec_df)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijp_0RC6Xb6z"
      },
      "source": [
        "### Apply kmeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ8K3cFj01Zj"
      },
      "source": [
        "# apply kmeans\n",
        "labels_text = kmeans(text_vec)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghmdnG4KZL-T"
      },
      "source": [
        "### The nmi score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bra2_pTyZN5j",
        "outputId": "8cee558c-11ad-4a36-ab6c-00cd4b34e642"
      },
      "source": [
        "# comput the nmi score\n",
        "nmi_sc = normalized_mutual_info_score(true_label, list(labels_text))\n",
        "print('The nmi score of text clustering with k-means is: ', nmi_sc)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nmi score of text clustering with k-means is:  0.08210659584960936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aIGjUUNXgOC"
      },
      "source": [
        "## Text clustering + Node clustering\n",
        "We have the embedding matrix base on the graph with embedding size 64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfuBgqfbXuOY",
        "outputId": "6c55287e-48f6-485d-8bef-dc9e48537149"
      },
      "source": [
        "node_vec.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18720, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIWo4ytrX2Uy"
      },
      "source": [
        "And the embedding matrix using title of each document with embedding size 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGEu3CmhYBIF",
        "outputId": "9f487293-ad7a-41df-a30c-70b516c2ca45"
      },
      "source": [
        "text_vec_df.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18720, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTqVf22oYLpf"
      },
      "source": [
        "Now we can just column bind those two dataframe and the apply kmeans."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qKTOnQIYgDd",
        "outputId": "0377ce61-f547-4a89-dafd-ee672842a135"
      },
      "source": [
        "text_and_node_vec = pd.concat([text_vec_df, node_vec],axis=1)\n",
        "text_and_node_vec.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18720, 164)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQsdXE-O01cq"
      },
      "source": [
        "# turn the NaN values to number\n",
        "text_and_node_vec = np.nan_to_num(text_and_node_vec)\n",
        "label_comb = kmeans(text_and_node_vec)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2H7oErlY-xU"
      },
      "source": [
        "### The nmi score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFW4hZ1_sv7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594747e5-ec4c-43a9-fac5-760962fa95c4"
      },
      "source": [
        "nmi_sc = normalized_mutual_info_score(true_label, label_comb)\n",
        "print('The nmi score of the combination of text clustering and node clustering is: ', nmi_sc)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nmi score of the combination of text clustering and node clustering is:  0.2993665902939315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMwevb7LnwIg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}